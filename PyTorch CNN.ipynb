{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Programming Task: Digit recognition using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Complete the code for the ConvNet class given below using the network description from supplement pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialize the base class nn.Module\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Initializa all the layers with their parameters\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(20 * 12 * 12, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional layer with ReLu activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Pooling layer\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten layer\n",
    "        x = x.view(-1, 20 * 12 * 12)\n",
    "        \n",
    "        # Fully connected layer with ReLu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Fully connected layer that returns probabilities of classes\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2880, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Train the CNN and observe the difference in performance in comparison to the feed-forward\n",
    "network from the task 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper parameters.\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set.\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = Data.DataLoader(dataset = trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = Data.DataLoader(dataset = testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the loss function and the optimization criteria\n",
    "# Loss Function - cross entropy loss, most common for multi class clasification\n",
    "model = ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer - popular in deep learning nowadays\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 200] loss: 0.527\n",
      "[1, 400] loss: 0.166\n",
      "[1, 600] loss: 0.119\n",
      "[1, 800] loss: 0.106\n",
      "[2, 200] loss: 0.069\n",
      "[2, 400] loss: 0.071\n",
      "[2, 600] loss: 0.066\n",
      "[2, 800] loss: 0.059\n",
      "[3, 200] loss: 0.047\n",
      "[3, 400] loss: 0.053\n",
      "[3, 600] loss: 0.048\n",
      "[3, 800] loss: 0.044\n",
      "[4, 200] loss: 0.032\n",
      "[4, 400] loss: 0.032\n",
      "[4, 600] loss: 0.036\n",
      "[4, 800] loss: 0.037\n",
      "[5, 200] loss: 0.024\n",
      "[5, 400] loss: 0.027\n",
      "[5, 600] loss: 0.033\n",
      "[5, 800] loss: 0.034\n",
      "[6, 200] loss: 0.020\n",
      "[6, 400] loss: 0.021\n",
      "[6, 600] loss: 0.030\n",
      "[6, 800] loss: 0.026\n",
      "[7, 200] loss: 0.016\n",
      "[7, 400] loss: 0.020\n",
      "[7, 600] loss: 0.021\n",
      "[7, 800] loss: 0.020\n",
      "[8, 200] loss: 0.016\n",
      "[8, 400] loss: 0.012\n",
      "[8, 600] loss: 0.018\n",
      "[8, 800] loss: 0.014\n",
      "[9, 200] loss: 0.011\n",
      "[9, 400] loss: 0.013\n",
      "[9, 600] loss: 0.013\n",
      "[9, 800] loss: 0.021\n",
      "[10, 200] loss: 0.010\n",
      "[10, 400] loss: 0.014\n",
      "[10, 600] loss: 0.012\n",
      "[10, 800] loss: 0.010\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Run the main training loop\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute the predicted outputs by passing inputs to the model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.81%\n"
     ]
    }
   ],
   "source": [
    "# Run the testing loop\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradient is needed for evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # Forward pass to get outputs\n",
    "        outputs = model(images)\n",
    "\n",
    "        # The class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Calculate the number of learnable parameters and the output shape in each layer. Verify your\n",
    "answers with model summary. (Refer last cell of the tutorial notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ConvNet                                  [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 20, 24, 24]           520\n",
       "├─MaxPool2d: 1-2                         [1, 20, 12, 12]           --\n",
       "├─Linear: 1-3                            [1, 100]                  288,100\n",
       "├─Linear: 1-4                            [1, 10]                   1,010\n",
       "==========================================================================================\n",
       "Total params: 289,630\n",
       "Trainable params: 289,630\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.59\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.09\n",
       "Params size (MB): 1.16\n",
       "Estimated Total Size (MB): 1.25\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_params = (5 * 5 * 1 * 20) + 20\n",
    "maxpool_params = 0 #non trainable\n",
    "flatten = 0 #non trainable\n",
    "flatten_size = 20 * 12 * 12\n",
    "fullyconn1_params = (flatten_size * 100) + 100\n",
    "fullyconn2_params = 100 * 10 + 10\n",
    "\n",
    "params = conv2d_params + fullyconn1_params + fullyconn2_params\n",
    "\n",
    "print(params)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "model = ConvNet()\n",
    "summary(model, input_size=(1, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c617624a7fd88b4018bd9e75be0d58c4afb6a334791d511af9b9a5162b5af2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
